{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# mask detection\n","\n","Here I am going to detect whether a person is wearing mask or not. I am focussing on only two classes that are 'face_with_mask' and face_no_mask'."]},{"cell_type":"markdown","metadata":{},"source":["## Importing Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import numpy as np \n","import pandas as pd \n","import os\n","import matplotlib.pyplot as plt\n","import cv2\n","import matplotlib.patches as patches\n","import tensorflow as tf\n","from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout\n","from keras.models import Sequential"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["pip install mtcnn"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from mtcnn.mtcnn import MTCNN"]},{"cell_type":"markdown","metadata":{},"source":["# Loading datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["images=os.path.join(\"/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images\")\n","annotations=os.path.join(\"/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/annotations\")\n","train=pd.read_csv(os.path.join(\"/kaggle/input/face-mask-detection-dataset/train.csv\"))\n","submission=pd.read_csv(os.path.join(\"/kaggle/input/face-mask-detection-dataset/submission.csv\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(len(train))\n","train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(len(submission))\n","submission.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["len(os.listdir(images))"]},{"cell_type":"markdown","metadata":{},"source":["## We are having 6024 images."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["a=os.listdir(images)\n","b=os.listdir(annotations)\n","a.sort()\n","b.sort()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(len(b),len(a))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_images=a[1698:]\n","test_images=a[:1698]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_images[0]"]},{"cell_type":"markdown","metadata":{},"source":["Let's see some of the images."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["img=plt.imread(os.path.join(images,test_images[0]))\n","plt.imshow(img)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["img=plt.imread(os.path.join(images,train_images[1]))\n","plt.imshow(img)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["options=['face_with_mask','face_no_mask']\n","train= train[train['classname'].isin(options)]\n","train.sort_values('name',axis=0,inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["bbox=[]\n","for i in range(len(train)):\n","    arr=[]\n","    for j in train.iloc[i][[\"x1\",'x2','y1','y2']]:\n","        arr.append(j)\n","    bbox.append(arr)\n","train[\"bbox\"]=bbox  \n","def get_boxes(id):\n","    boxes=[]\n","    for i in train[train[\"name\"]==str(id)][\"bbox\"]:\n","        boxes.append(i)\n","    return boxes\n","print(get_boxes(train_images[3]))\n","image=train_images[3]\n","\n","img=plt.imread(os.path.join(images,image))\n","\n","fig,ax = plt.subplots(1)\n","ax.imshow(img)\n","boxes=get_boxes(image)\n","for box in boxes:\n","    rect = patches.Rectangle((box[0],box[1]),box[2]-box[0],box[3]-box[1],linewidth=2,edgecolor='r',facecolor='none')\n","    ax.add_patch(rect)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["image=train_images[5]\n","\n","img=plt.imread(os.path.join(images,image))\n","\n","fig,ax = plt.subplots(1)\n","ax.imshow(img)\n","boxes=get_boxes(image)\n","for box in boxes:\n","    rect = patches.Rectangle((box[0],box[1]),box[2]-box[0],box[3]-box[1],linewidth=2,edgecolor='r',facecolor='none')\n","    ax.add_patch(rect)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.bar(['face_with_mask','face_no_mask'],train.classname.value_counts())"]},{"cell_type":"markdown","metadata":{},"source":["# Creating training data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["img_size=50\n","data=[]\n","path='/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images/'\n","def create_data():\n","       for i in range(len(train)):\n","            arr=[]\n","            for j in train.iloc[i]:\n","                   arr.append(j)\n","            img_array=cv2.imread(os.path.join(images,arr[0]),cv2.IMREAD_GRAYSCALE)\n","            crop_image = img_array[arr[2]:arr[4],arr[1]:arr[3]]\n","            new_img_array=cv2.resize(crop_image,(img_size,img_size))\n","            data.append([new_img_array,arr[5]])\n","create_data()      "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data[0][0]\n","plt.imshow(data[0][0])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["x=[]\n","y=[]\n","for features, labels in data:\n","    x.append(features)\n","    y.append(labels)\n","from sklearn.preprocessing import LabelEncoder\n","lbl=LabelEncoder()\n","y=lbl.fit_transform(y)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["x=np.array(x).reshape(-1,50,50,1)\n","x=tf.keras.utils.normalize(x,axis=1)\n","from keras.utils import to_categorical\n","y = to_categorical(y)"]},{"cell_type":"markdown","metadata":{},"source":["# Model Fitting"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from keras.layers import LSTM\n","model=Sequential()\n","model.add(Conv2D(100,(3,3),input_shape=x.shape[1:],activation='relu',strides=2))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Conv2D(64,(3,3),activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Flatten())\n","model.add(Dense(50, activation='relu'))\n","model.add(Dropout(0.2))\n","\n","model.add(Dense(2, activation='softmax'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","opt = tf.keras.optimizers.Adam(lr=1e-3, decay=1e-5)\n","model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) \n","model.fit(x,y,epochs=30,batch_size=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["detector=MTCNN()\n","img=plt.imread(os.path.join(images,test_images[0]))\n","face=detector.detect_faces(img)\n","for face in face:\n","        bounding_box=face['box']\n","        x=cv2.rectangle(img,\n","              (bounding_box[0], bounding_box[1]),\n","              (bounding_box[0]+bounding_box[2], bounding_box[1] + bounding_box[3]),\n","              (0,155,255),\n","              10)\n","        plt.imshow(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["img=plt.imread(os.path.join(images,test_images[3]))\n","face=detector.detect_faces(img)\n","for face in face:\n","        bounding_box=face['box']\n","        x=cv2.rectangle(img,\n","              (bounding_box[0], bounding_box[1]),\n","              (bounding_box[0]+bounding_box[2], bounding_box[1] + bounding_box[3]),\n","              (0,155,255),\n","              10)\n","        plt.imshow(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["detector=MTCNN()\n","test_df=[]\n","for image in test_images:\n","    img=plt.imread(os.path.join(images,image))\n","    faces=detector.detect_faces(img)\n","    test=[]\n","    for face in faces:\n","        bounding_box=face['box']\n","        test.append([image,bounding_box])\n","    test_df.append(test)\n","test=[]\n","for i in test_df:\n","    if len(i)>0:\n","        if len(i)==1:\n","            test.append(i[0])\n","        else:\n","            for j in i:\n","                test.append(j)  \n","sub=[]\n","rest_image=[]\n","for i in test:\n","    sub.append(i[0])\n","for image in test_images:\n","    if image not in sub:\n","        rest_image.append(image) \n","detector=MTCNN()\n","test_df_=[]\n","for image in rest_image:\n","    img=cv2.imread(os.path.join(images,image))\n","    faces=detector.detect_faces(img)\n","    test_=[]\n","    for face in faces:\n","        bounding_box=face['box']\n","        test_.append([image,bounding_box])\n","    test_df_.append(test_) \n","for i in test_df_:\n","    if len(i)>0:\n","        if len(i)==1:\n","            test.append(i[0])\n","        else:\n","            for j in i:\n","                test.append(j)      "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["negative=[]\n","for i in test:\n","    for j in i[1]:\n","        if j<0:\n","            negative.append(i)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_data=[]\n","def create_test_data():\n","            for j in test:\n","                if j not in negative:\n","                    img=cv2.imread(os.path.join(images,j[0]),cv2.IMREAD_GRAYSCALE)\n","                    img=img[j[1][1]:j[1][1]+j[1][3],j[1][0]:j[1][0]+j[1][2]]\n","                    new_img=cv2.resize(img,(50,50))\n","                    new_img=new_img.reshape(-1,50,50,1)\n","                    predict=model.predict(new_img)\n","                    test_data.append([j,predict])\n","\n","create_test_data()      "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["image=[]\n","classname=[]\n","for i,j in test_data:\n","    classname.append(np.argmax(j))\n","    image.append(i)\n","df=pd.DataFrame(columns=['image','classname'])\n","df['image']=image\n","df['classname']=classname\n","df['classname']=lbl.inverse_transform(df['classname'])\n","image=[]\n","x1=[]\n","x2=[]\n","y1=[]\n","y2=[]\n","for i in df['image']:\n","    image.append(i[0])\n","    x1.append(i[1][0])\n","    x2.append(i[1][1])\n","    y1.append(i[1][2])\n","    y2.append(i[1][3])\n","df['name']=image\n","df['x1']=x1\n","df['x2']=x2\n","df['y1']=y1\n","df['y2']=y2    \n","df.drop(['image'],axis=1,inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.sort_values('name',axis=0,inplace=True,ascending=False)\n","df.to_csv('submission_1.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
